{
  "judge_model": {
    "id": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "max_tokens": 1024,
    "temperature": 0.0
  },
  "evaluation_criteria": {
    "speech_recognition": "How accurately did the system recognize the spoken input?",
    "tool_calling_accuracy": "How accurately did the system call the expected function/tool?",
    "response_relevance": "How relevant is the response to the recognized input?",
    "response_correctness": "How accurate is the information provided in the response?",
    "completeness": "Does the response provide all necessary information to fully answer the query?",
    "clarity": "Is the response clear, well-structured, and easy to understand?"
  },
  "prompt_template": "You are an expert evaluator for speech-to-speech AI interactions in a retail context.\nYour task is to evaluate the quality and accuracy of a retail assistant AI's responses.\n\nPlease analyze the following information and provide scores based on the criteria below.\nEXPECTED USER INPUT: \"{expected_user_input}\"\nTRANSCRIBED USER INPUT: \"{user_input}\"\n\nEXPECTED MODEL RESPONSE: \"{expected_response}\"\nTRANSCRIBED MODEL RESPONSE: \"{transcribed_response}\"\n\nEXPECTED FUNCTION CALL: \"{expected_function}\"\nACTUAL FUNCTION CALLS:\n\"{tool_spans}\"\n\nPlease evaluate the response based on the following criteria:\n{criteria_text}\n\nFor each criterion, provide:\n1. A score from 1-5 (where 1 is poor and 5 is excellent)\n2. A brief explanation for your score\n\nThen provide an overall score from 1-5 and a summary of your evaluation.\n\nYou MUST format your response as a JSON object with the following structure:\n{{\n    \"criteria\": {{\n    \"speech_recognition\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }},\n    \"tool_calling_accuracy\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }},\n    \"response_relevance\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }},\n    \"response_correctness\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }},\n    \"completeness\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }},\n    \"clarity\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }}\n  }},\n  \"overall\": {{\n    \"score\": <score>,\n    \"summary\": \"<summary>\"\n  }}\n}}"
}
