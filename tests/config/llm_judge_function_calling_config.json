{
  "judge_model": {
    "id": "anthropic.claude-3-sonnet-20240229-v1:0",
    "max_tokens": 1024,
    "temperature": 0.0
  },
  "evaluation_criteria": {
    "correctness": "Does the response correctly answer the query with accurate information?",
    "relevance": "Is the response directly relevant to the user's query?",
    "completeness": "Does the response provide all necessary information to fully answer the query?",
    "clarity": "Is the response clear, well-structured, and easy to understand?"
  },
  "prompt_template": "You are an expert evaluator for retail assistant AI responses. Your task is to evaluate the quality of a response to a user query.\n\nUSER QUERY: \"{query}\"\n\nMODEL RESPONSE: \"{response}\"\n\n EXPECTED RESPONSE: \"{expected_response}\"\n\nPlease evaluate the response based on the following criteria:\n{criteria_text}\n\nFor each criterion, provide:\n1. A score from 1-5 (where 1 is poor and 5 is excellent)\n2. A brief explanation for your score\n\nThen provide an overall score from 1-5 and a summary of your evaluation.\n\nFormat your response as JSON with the following structure:\n{{\n  \"criteria\": {{\n    \"correctness\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }}, \"relevance\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }},\n    \"completeness\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }},\n    \"clarity\": {{\n      \"score\": <score>,\n      \"explanation\": \"<explanation>\"\n    }}\n  }},\n  \"overall\": {{\n    \"score\": <score>,\n    \"summary\": \"<summary>\"\n  }}\n}}"
}
